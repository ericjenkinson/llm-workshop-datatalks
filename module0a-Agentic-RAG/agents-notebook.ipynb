{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bacdb48e-d72d-4668-be5b-bb0f1eb89222",
   "metadata": {},
   "source": [
    "Follow along this tutorial: https://github.com/alexeygrigorev/rag-agents-workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73431ce2-07a0-460d-835a-6e5e79ecce19",
   "metadata": {},
   "source": [
    "## Part 0: Basic RAG\n",
    "\n",
    "### RAG\n",
    "\n",
    "RAG consists of 3 parts:\n",
    "\n",
    "* Search\n",
    "* Prompt\n",
    "* LLM\n",
    "\n",
    "So in python it looks like that:\n",
    "```python\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer\n",
    "```    \n",
    "Let's implement each component step-by-step\n",
    "\n",
    "## Search\n",
    "\n",
    "First, we implement a basic search function that will query our FAQ database. This function takes a query string and returns relevant documents.\n",
    "\n",
    "We will use minsearch for that, so let's install it\n",
    "```\n",
    "pip install minsearch\n",
    "```\n",
    "Get the documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5502611c-5b20-4099-a404-56095feb17ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: minsearch in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.0.2)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (from minsearch) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (from minsearch) (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->minsearch) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->minsearch) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->minsearch) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->minsearch) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->minsearch) (1.17.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->minsearch) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->minsearch) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->minsearch) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d77c853-50bf-48e4-98bc-5cb61a0db783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe13361-c047-4770-a6f8-5471b2452264",
   "metadata": {},
   "source": [
    "Index them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a244f2d-2ad7-410c-8fa7-e3ab1b1f008c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x799384de0cb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minsearch import AppendableIndex\n",
    "\n",
    "index = AppendableIndex(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142aff0b-3e01-4273-9f1c-5b6b5763526a",
   "metadata": {},
   "source": [
    "Now Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee4e6aa5-bef0-4322-b540-f1712c7a3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0533e4c-80e4-45d9-bcc4-fe1daa8b8432",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "---\n",
    "* This function is the foundation of our RAG system\n",
    "* It looks up in the FAQ to find relevant information\n",
    "* The result is used to build context for the LLM\n",
    "\n",
    "## Prompt\n",
    "\n",
    "We create a function to format the search results into a structured context that our LLM can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d277dc15-db73-4e76-a73a-f13221e8fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5014c679-74fb-48da-af49-631e67603205",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "* Takes search results\n",
    "* Formats each document\n",
    "* Put everything in a prompt\n",
    "\n",
    "## The RAG flow\n",
    "\n",
    "We add a call to an LLM and combine everything into a complete RAG pipeline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2531e1eb-46d5-4075-8656-7f6a515532db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0076580-f626-4cf9-b09b-f2651ba9b9b7",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "* ```build_prompt```: Formats the search results into a prompt\n",
    "* ```llm```: Makes the API call to the language model\n",
    "* ```rag```: Combines search and LLM into a single function\n",
    "\n",
    "## Part 1: Agentic RAG\n",
    "---\n",
    "Now let's make our flow agentic\n",
    "\n",
    "### Agents and Agentic flows\n",
    "---\n",
    "Agents are AI systems that can:\n",
    "\n",
    "* Make decisions about what actions to take\n",
    "* Use tools to accomplish tasks\n",
    "* Maintain state and context\n",
    "* Learn from previous interactions\n",
    "* Work towards specific goals\n",
    "\n",
    "Agentic flow is not necessarily a completely independent agent, but it can still make some decisions during the flow execution\n",
    "\n",
    "A typical agentic flow consists of:\n",
    "\n",
    "1 Receiving a user request\n",
    "2 Analyzing the request and available tools\n",
    "3 Deciding on the next action\n",
    "4 Executing the action using appropriate tools\n",
    "5 Evaluating the results\n",
    "6 Either completing the task or continuing with more actions\n",
    "\n",
    "The key difference from basic RAG is that agents can:\n",
    "\n",
    "* Make multiple search queries\n",
    "* Combine information from different sources\n",
    "* Decide when to stop searching\n",
    "* Use their own knowledge when appropriate\n",
    "* Chain multiple actions together\n",
    "\n",
    "So in agentic RAG, the system\n",
    "\n",
    "* has access to the history of previous actions\n",
    "* makes decisions independently based on the current information and the previous actions\n",
    "\n",
    "Let's implement this step by step.\n",
    "\n",
    "## Making RAG more agentic\n",
    "---\n",
    "First, we'll take the prompt we have so far and make it a little more \"agentic\":\n",
    "\n",
    "* Tell the LLM that it can answer the question directly or look up context\n",
    "* Provide output templates\n",
    "* Show clearly what's the source of the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59a4ae73-6b05-4f93-9cae-03b8a114c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "At the beginning the context is EMPTY.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "If CONTEXT is EMPTY, you can use our FAQ database.\n",
    "In this case, use the following output template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\"\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e998341-b383-4cde-92d1-17d00f19e0de",
   "metadata": {},
   "source": [
    "Let's use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba601b0-1372-4904-b0e1-ac8eb3f9104d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "how do I run docker on gentoo?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"To run Docker on Gentoo, you'll need to follow these steps: 1. Install the Docker package. You can do this by adding `app-containers/docker` to your package manager. Run `emerge app-containers/docker` in the terminal. 2. Once installed, you need to start the Docker service. You can do this with the command `systemctl start docker` and ensure it runs on boot with `systemctl enable docker`. 3. Add your user to the 'docker' group to run Docker commands without sudo by executing `usermod -aG docker your_username`. 4. Finally, you can verify the installation by running `docker --version` and try a simple command like `docker run hello-world` to make sure everything is set up correctly.\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"how do I run docker on gentoo?\"\n",
    "context = \"EMPTY\"\n",
    "\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt)\n",
    "\n",
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb32b08f-ff54-45bf-b5b4-d74bcff23a16",
   "metadata": {},
   "source": [
    "If we ask for somthing that it can't answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03a26e04-8d74-4ae9-b13d-fbcf5a280d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"The student's question about how to join the course requires information that is not available in the provided context, and I need to refer to the FAQ database for accurate details.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"how do I join the course?\"\n",
    "context = \"EMPTY\"\n",
    "\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0880b4-8691-4902-ace5-d0b97d4d850e",
   "metadata": {},
   "source": [
    "Let's make the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdcb09cd-4e1b-4ced-a0b4-755dbc83f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    return context.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b606f65-6dae-4dd0-a31e-2b1a40e8211c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "how do I join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "search_results = search(question)\n",
    "context = build_context(search_results)\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f293b4-6773-4b94-b545-9dde9af9e01e",
   "metadata": {},
   "source": [
    "Now we can try the query again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "350889c9-ecda-4e31-b1f3-e1ecc86c8f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"To join the course, make sure to register before the course starts using the provided link. The course officially begins on January 15, 2024, at 17:00. Additionally, you can join the course's Telegram channel for announcements and be sure to register in DataTalks.Club's Slack and join the relevant channel.\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9b3f90-a7b2-4468-8173-73b7b3228db0",
   "metadata": {},
   "source": [
    "Let's put this together:\n",
    "\n",
    "* First attempt to answer it with our know knowledge\n",
    "* If needed, do the lookup and then answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3080af8-af9f-42de-9734-c2565f9b78f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def agentic_rag_v1(question):\n",
    "    context = \"EMPTY\"\n",
    "    prompt = prompt_template.format(question=question, context=context)\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(answer)\n",
    "\n",
    "    if answer['action'] == 'SEARCH':\n",
    "        print('need to perform search...')\n",
    "        search_results = search(question)\n",
    "        context = build_context(search_results)\n",
    "        \n",
    "        prompt = prompt_template.format(question=question, context=context)\n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(answer)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3c8d1f-57de-42c8-a5bd-d9416f6f2263",
   "metadata": {},
   "source": [
    "Test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "043e5216-abf5-4bb2-8c0b-26f4ce1b47a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'SEARCH', 'reasoning': \"The context is empty, so I need to look for information in the FAQ database to answer the student's question about how to join the course.\"}\n",
      "need to perform search...\n",
      "{'action': 'ANSWER', 'answer': 'To join the course, you need to register before the course starts. Use the provided registration link for this. Even if the course has already started, you can still submit homework, but make sure to keep up with deadlines for the final projects.', 'source': 'CONTEXT'}\n",
      "{'action': 'ANSWER', 'answer': 'To patch KDE under FreeBSD, you typically follow these steps:\\n\\n1. **Install the necessary tools**: Make sure you have the ports collection installed and updated. You can do this by running:\\n   ```\\n   portsnap fetch extract\\n   ```\\n   and then updating the ports with:\\n   ```\\n   portsnap fetch update\\n   ```\\n\\n2. **Navigate to the KDE port**: Go to the directory of the KDE port you want to patch. For example, for KDE5, the path might look like this:\\n   ```\\n   cd /usr/ports/x11/kde5/\\n   ```\\n\\n3. **Fetch the latest patches**: If there are patches available, you can fetch them from the FreeBSD repositories to apply to the port. This can usually be done using:\\n   ```\\n   make fetch\\n   ```\\n   This will download the latest distfiles and patches.\\n\\n4. **Apply your custom patch**: If you have a specific patch that you want to apply, you can place it in the relevant patches directory, usually located in\\n   ```\\n   /usr/ports/x11/kde5/files/patch-* \\n   ```\\n5. **Build the port**: After preparing the patches, you can build the port with:\\n   ```\\n   make install clean\\n   ```\\n   This will apply the patches and install KDE with the new changes.\\n\\n6. **Test your installation**: Finally, start KDE and test if the patches applied are functioning as expected.\\n\\nRemember to refer to FreeBSD documentation for any specific commands or additional steps that might be necessary based on your KDE version.', 'source': 'OWN_KNOWLEDGE'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': 'To patch KDE under FreeBSD, you typically follow these steps:\\n\\n1. **Install the necessary tools**: Make sure you have the ports collection installed and updated. You can do this by running:\\n   ```\\n   portsnap fetch extract\\n   ```\\n   and then updating the ports with:\\n   ```\\n   portsnap fetch update\\n   ```\\n\\n2. **Navigate to the KDE port**: Go to the directory of the KDE port you want to patch. For example, for KDE5, the path might look like this:\\n   ```\\n   cd /usr/ports/x11/kde5/\\n   ```\\n\\n3. **Fetch the latest patches**: If there are patches available, you can fetch them from the FreeBSD repositories to apply to the port. This can usually be done using:\\n   ```\\n   make fetch\\n   ```\\n   This will download the latest distfiles and patches.\\n\\n4. **Apply your custom patch**: If you have a specific patch that you want to apply, you can place it in the relevant patches directory, usually located in\\n   ```\\n   /usr/ports/x11/kde5/files/patch-* \\n   ```\\n5. **Build the port**: After preparing the patches, you can build the port with:\\n   ```\\n   make install clean\\n   ```\\n   This will apply the patches and install KDE with the new changes.\\n\\n6. **Test your installation**: Finally, start KDE and test if the patches applied are functioning as expected.\\n\\nRemember to refer to FreeBSD documentation for any specific commands or additional steps that might be necessary based on your KDE version.',\n",
       " 'source': 'OWN_KNOWLEDGE'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentic_rag_v1('how do I join the course?')\n",
    "agentic_rag_v1('how patch KDE under FreeBSD?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230a119f-3f79-46d8-a093-c1e91c5da22f",
   "metadata": {},
   "source": [
    "## Part 2: Agentic search\n",
    "---\n",
    "So far we had two actions only: search and answer.\n",
    "\n",
    "But we can let our \"agent\" formulate one or more search queries - and do it for a few iterations until we found an answer\n",
    "\n",
    "Let's build a prompt:\n",
    "\n",
    "* List available actions:\n",
    "    * Search in FAQ\n",
    "    * Answer using own knowledge\n",
    "    * Answer using information extracted from FAQ\n",
    "* Provide access to the previous actions\n",
    "* Have clear stop criteria (no more than X iterations)\n",
    "* We also specify the output format, so it's easier to parse it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d0e64cc-c6f8-4c7b-a0df-b85d550152e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "\n",
    "The CONTEXT is build with the documents from our FAQ database.\n",
    "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
    "from FAQ to and add them to the context.\n",
    "PREVIOUS_ACTIONS contains the actions you already performed.\n",
    "\n",
    "At the beginning the CONTEXT is empty.\n",
    "\n",
    "You can perform the following actions:\n",
    "\n",
    "- Search in the FAQ database to get more data for the CONTEXT\n",
    "- Answer the question using the CONTEXT\n",
    "- Answer the question using your own knowledge\n",
    "\n",
    "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
    "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
    "\n",
    "Don't use search queries used at the previous iterations.\n",
    "\n",
    "Don't repeat previously performed actions.\n",
    "\n",
    "Don't perform more than {max_iterations} iterations for a given student question.\n",
    "The current iteration number: {iteration_number}. If we exceed the allowed number \n",
    "of iterations, give the best possible answer with the provided information.\n",
    "\n",
    "Output templates:\n",
    "\n",
    "If you want to perform search, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\",\n",
    "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER_CONTEXT\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<SEARCH_QUERIES>\n",
    "{search_queries}\n",
    "</SEARCH_QUERIES>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "<PREVIOUS_ACTIONS>\n",
    "{previous_actions}\n",
    "</PREVIOUS_ACTIONS>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3742695f-6a8c-4f1e-a319-51759e48b009",
   "metadata": {},
   "source": [
    "Our code becomes more complicated. For the first iteration, we have:question = \"how do I join the course?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af46320a-ce17-439a-b338-46b492994198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n"
     ]
    }
   ],
   "source": [
    "search_queries = []\n",
    "search_results = []\n",
    "previous_actions = []\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=3,\n",
    "    iteration_number=1\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4abd75e1-e4b4-450a-91bf-0ea56f08f5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"The student is asking about the process to join the course, which likely involves specific steps or requirements that would be outlined in the FAQ database. It's important to verify this information for accuracy.\",\n",
      "  \"keywords\": [\n",
      "    \"join course\",\n",
      "    \"enrollment process\",\n",
      "    \"how to sign up for the course\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "answer = json.loads(answer_json)\n",
    "print(json.dumps(answer, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2a6194-79d1-4b02-8eac-f3a02dec1270",
   "metadata": {},
   "source": [
    "We need to save the actions, so let's do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cfea6d1-9b8e-4cdb-8569-33fc042fd032",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_actions.append(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9392f6-47c9-4bdc-add9-6bb7a2dcf5c9",
   "metadata": {},
   "source": [
    "Save the search queries and perform the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7072764b-2e1c-469f-bf8c-294bf5841b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = answer['keywords']\n",
    "search_queries.extend(keywords)\n",
    "\n",
    "for k in keywords:\n",
    "    res = search(k)\n",
    "    search_results.extend(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e893546-ffb2-43bc-895c-b69ed2a03442",
   "metadata": {},
   "source": [
    "Some of the search results will be duplicates, so we need to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d68b8a9-9897-4fef-9736-10bdfe42bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedup(seq):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for el in seq:\n",
    "        _id = el['_id']\n",
    "        if _id in seen:\n",
    "            continue\n",
    "        seen.add(_id)\n",
    "        result.append(el)\n",
    "    return result\n",
    "\n",
    "search_results = dedup(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d610f4-8bfe-4107-956c-962328bbf16d",
   "metadata": {},
   "source": [
    "Now let's make another iteration - use the same code as previously, but remove variable initialization and increase the iteration number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ca60f22-8752-48cd-98cb-2f34c99107c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "join course\n",
      "enrollment process\n",
      "how to sign up for the course\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: lsRuntimeError: Java gateway process exited before sending its port number\n",
      "answer: After installing all including pyspark (and it is successfully imported), but then running this script on the jupyter notebook\n",
      "import pyspark\n",
      "from pyspark.sql import SparkSession\n",
      "spark = SparkSession.builder \\\n",
      ".master(\"local[*]\") \\\n",
      ".appName('test') \\\n",
      ".getOrCreate()\n",
      "df = spark.read \\\n",
      ".option(\"header\", \"true\") \\\n",
      ".csv('taxi+_zone_lookup.csv')\n",
      "df.show()\n",
      "it gives the error:\n",
      "RuntimeError: Java gateway process exited before sending its port number\n",
      "✅The solution (for me) was:\n",
      "pip install findspark on the command line and then\n",
      "Add\n",
      "import findspark\n",
      "findspark.init()\n",
      "to the top of the script.\n",
      "Another possible solution is:\n",
      "Check that pyspark is pointing to the correct location.\n",
      "Run pyspark.__file__. It should be list /home/<your user name>/spark/spark-3.0.3-bin-hadoop3.2/python/pyspark/__init__.py if you followed the videos.\n",
      "If it is pointing to your python site-packages remove the pyspark directory there and check that you have added the correct exports to you .bashrc file and that there are not any other exports which might supersede the ones provided in the course content.\n",
      "To add to the solution above, if the errors persist in regards to setting the correct path for spark,  an alternative solution for permanent path setting solve the error is  to set environment variables on system and user environment variables following this tutorial: Install Apache PySpark on Windows PC | Apache Spark Installation Guide\n",
      "Once everything is installed, skip to 7:14 to set up environment variables. This allows for the environment variables to be set permanently.\n",
      "\n",
      "section: Module 2: Workflow Orchestration\n",
      "question: Process to download the VSC using Pandas is killed right away\n",
      "answer: pd.read_csv\n",
      "df_iter = pd.read_csv(dataset_url, iterator=True, chunksize=100000)\n",
      "The data needs to be appended to the parquet file using the fastparquet engine\n",
      "df.to_parquet(path, compression=\"gzip\", engine='fastparquet', append=True)\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Docker-Compose - Errors pertaining to docker-compose.yml and pgadmin setup\n",
      "answer: For everyone who's having problem with Docker compose, getting the data in postgres and similar issues, please take care of the following:\n",
      "create a new volume on docker (either using the command line or docker desktop app)\n",
      "make the following changes to your docker-compose.yml file (see attachment)\n",
      "set low_memory=false when importing the csv file (df = pd.read_csv('yellow_tripdata_2021-01.csv', nrows=1000, low_memory=False))\n",
      "use the below function (in the upload-data.ipynb) for better tracking of your ingestion process (see attachment)\n",
      "Order of execution:\n",
      "(1) open terminal in 2_docker_sql folder and run docker compose up\n",
      "(2) ensure no other containers are running except the one you just executed (pgadmin and pgdatabase)\n",
      "(3) open jupyter notebook and begin the data ingestion\n",
      "(4) open pgadmin and set up a server (make sure you use the same configurations as your docker-compose.yml file like the same name (pgdatabase), port, databasename (ny_taxi) etc.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "\n",
      "section: Module 2: Workflow Orchestration\n",
      "question: GCP - 2.2.7d Part 2 - Getting error when you run terraform apply\n",
      "answer: If you get the following error\n",
      "You have to edit variables.tf on the gcp folder, set your project-id and region and zones properly. Then, run terraform apply again.\n",
      "You can find correct regions/zones here: https://cloud.google.com/compute/docs/regions-zones\n",
      "Deploying MAGE to GCP  with Terraform via the VM (2.2.7)\n",
      "FYI - It can take up to 20 minutes to deploy the MAGE Terraform files if you are using a GCP Virtual Machine. It is normal, so don’t interrupt the process or think it’s taking too long. If you have, make sure you run a terraform destroy before trying again as you will have likely partially created resources which will cause errors next time you run `terraform apply`.\n",
      "`terraform destroy` may not completely delete partial resources - go to Google Cloud Console and use the search bar at the top to search for the ‘app.name’ you declared in your variables.tf file; this will list all resources with that name - make sure you delete them all before running `terraform apply` again.\n",
      "Why are my GCP free credits going so fast? MAGE .tf files - Terraform Destroy not destroying all Resources\n",
      "I checked my GCP billing last night & the MAGE Terraform IaC didn't destroy a GCP Resource called Filestore as ‘mage-data-prep- it has been costing £5.01 of my free credits each day  I now have £151 left - Alexey has assured me that This amount WILL BE SUFFICIENT funds to finish the course. Note to anyone who had issues deploying the MAGE terraform code: check your billing account to see what you're being charged for (main menu - billing) (even if it's your free credits) and run a search for 'mage-data-prep' in the top bar just to be sure that your resources have been destroyed - if any come up delete them.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Is it possible to use tool “X” instead of the one tool you use in the course?\n",
      "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
      "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
      "Should you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The student is asking about the process to join the course, which likely involves specific steps or requirements that would be outlined in the FAQ database. It's important to verify this information for accuracy.\", \"keywords\": [\"join course\", \"enrollment process\", \"how to sign up for the course\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER_CONTEXT\",\n",
      "  \"answer\": \"To join the course, you need to register before it starts. The course will begin on 15th January 2024 at 17h00. You can register using the provided link. Additionally, it is recommended to subscribe to the course's public Google Calendar for updates and to join the course Telegram channel for announcements. Don't forget to register in DataTalks.Club's Slack and join the relevant channel.\",\n",
      "  \"source\": \"CONTEXT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# question = \"how do I join the course?\"\n",
    "\n",
    "# search_queries = []\n",
    "# search_results = []\n",
    "# previous_actions = []\n",
    "\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=3,\n",
    "    iteration_number=2\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "answer_json = llm(prompt)\n",
    "answer = json.loads(answer_json)\n",
    "print(json.dumps(answer, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a17bac1-bf53-4e0f-bd1b-54b9ecc9c227",
   "metadata": {},
   "source": [
    "Let's put everything together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7add4dea-5b86-4b2f-ba2f-d0b04b4d06ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"The student is asking for specific guidance on how to be successful in their first module. I need to gather information about success strategies and tips that may have been documented in the FAQ database.\",\n",
      "  \"keywords\": [\n",
      "    \"success tips for module 1\",\n",
      "    \"how to excel in module 1\",\n",
      "    \"strategies for module success\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #1...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "success tips for module 1\n",
      "strategies for module success\n",
      "how to excel in module 1\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The student is asking for specific guidance on how to be successful in their first module. I need to gather information about success strategies and tips that may have been documented in the FAQ database.\", \"keywords\": [\"success tips for module 1\", \"how to excel in module 1\", \"strategies for module success\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"Since the first search did not yield relevant information about success strategies for Module 1, I will look for broader resources on effective study habits and general tips for success in courses that might also apply to Module 1 specifically.\",\n",
      "  \"keywords\": [\n",
      "    \"effective study habits\",\n",
      "    \"course success strategies\",\n",
      "    \"tips for succeeding in online modules\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #2...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "course success strategies\n",
      "success tips for module 1\n",
      "how to excel in module 1\n",
      "effective study habits\n",
      "tips for succeeding in online modules\n",
      "strategies for module success\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Is it possible to use tool “X” instead of the one tool you use in the course?\n",
      "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
      "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
      "Should you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "\n",
      "section: General course-related questions\n",
      "question: Environment - Roadblock for Windows users in modules with *.sh (shell scripts).\n",
      "answer: Have no idea how past cohorts got past this as I haven't read old slack messages, and no FAQ entries that I can find.\n",
      "Later modules (module-05 & RisingWave workshop) use shell scripts in *.sh files and most Windows users not using WSL would hit a wall and cannot continue, even in git bash or MINGW64. This is why WSL environment setup is recommended from the start.\n",
      "\n",
      "section: Module 3: Data Warehousing\n",
      "question: GCS Bucket - I query my dataset and get a Bad character (ASCII 0) error?\n",
      "answer: Check the Schema\n",
      "You might have a wrong formatting\n",
      "Try to upload the CSV.GZ files without formatting or going through pandas via wget\n",
      "See this Slack conversation for helpful tips\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Hadoop - Exception in thread \"main\" java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z\n",
      "answer: If you are seeing this (or similar) error when attempting to write to parquet, it is likely an issue with your path variables.\n",
      "For Windows, create a new User Variable “HADOOP_HOME” that points to your Hadoop directory. Then add “%HADOOP_HOME%\\bin” to the PATH variable.\n",
      "Additional tips can be found here: https://stackoverflow.com/questions/41851066/exception-in-thread-main-java-lang-unsatisfiedlinkerror-org-apache-hadoop-io\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error: Failed to query available provider packages │ Could not retrieve the list of available versions for provider hashicorp/google: could not query │ provider registry for registry.terrafogorm.io/hashicorp/google: the request failed after 2 attempts, │ please try again later\n",
      "answer: It is an internet connectivity error, terraform is somehow not able to access the online registry. Check your VPN/Firewall settings (or just clear cookies or restart your network). Try terraform init again after this, it should work.\n",
      "\n",
      "section: Module 2: Workflow Orchestration\n",
      "question: Docker: container crashed with status code 137.\n",
      "answer: It means your container consumed all available RAM allocated to it. It can happen in particular when working on Question#3 in the homework as the dataset is relatively large and containers eat a lot of memory in general.\n",
      "I would recommend restarting your computer and only starting the necessary processes to run the container. If that doesn’t work, allocate more resources to docker. If also that doesn’t work because your workstation is a potato, you can use an online compute environment service like GitPod, which is free under under 50 hours / month of use.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The student is asking for specific guidance on how to be successful in their first module. I need to gather information about success strategies and tips that may have been documented in the FAQ database.\", \"keywords\": [\"success tips for module 1\", \"how to excel in module 1\", \"strategies for module success\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"Since the first search did not yield relevant information about success strategies for Module 1, I will look for broader resources on effective study habits and general tips for success in courses that might also apply to Module 1 specifically.\", \"keywords\": [\"effective study habits\", \"course success strategies\", \"tips for succeeding in online modules\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"The previous searches did not return specific strategies for success in Module 1. I will focus on searching for any general or specific resources that discuss strategies for success in online learning and course completion that might be applicable to Module 1.\",\n",
      "  \"keywords\": [\n",
      "    \"online learning success strategies\",\n",
      "    \"how to succeed in online courses\",\n",
      "    \"tips for succeeding in academic modules\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #3...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 3. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "how to succeed in online courses\n",
      "course success strategies\n",
      "success tips for module 1\n",
      "online learning success strategies\n",
      "effective study habits\n",
      "how to excel in module 1\n",
      "tips for succeeding in online modules\n",
      "strategies for module success\n",
      "tips for succeeding in academic modules\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Is it possible to use tool “X” instead of the one tool you use in the course?\n",
      "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
      "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
      "Should you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "\n",
      "section: General course-related questions\n",
      "question: Environment - Roadblock for Windows users in modules with *.sh (shell scripts).\n",
      "answer: Have no idea how past cohorts got past this as I haven't read old slack messages, and no FAQ entries that I can find.\n",
      "Later modules (module-05 & RisingWave workshop) use shell scripts in *.sh files and most Windows users not using WSL would hit a wall and cannot continue, even in git bash or MINGW64. This is why WSL environment setup is recommended from the start.\n",
      "\n",
      "section: Module 3: Data Warehousing\n",
      "question: GCS Bucket - I query my dataset and get a Bad character (ASCII 0) error?\n",
      "answer: Check the Schema\n",
      "You might have a wrong formatting\n",
      "Try to upload the CSV.GZ files without formatting or going through pandas via wget\n",
      "See this Slack conversation for helpful tips\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Hadoop - Exception in thread \"main\" java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z\n",
      "answer: If you are seeing this (or similar) error when attempting to write to parquet, it is likely an issue with your path variables.\n",
      "For Windows, create a new User Variable “HADOOP_HOME” that points to your Hadoop directory. Then add “%HADOOP_HOME%\\bin” to the PATH variable.\n",
      "Additional tips can be found here: https://stackoverflow.com/questions/41851066/exception-in-thread-main-java-lang-unsatisfiedlinkerror-org-apache-hadoop-io\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error: Failed to query available provider packages │ Could not retrieve the list of available versions for provider hashicorp/google: could not query │ provider registry for registry.terrafogorm.io/hashicorp/google: the request failed after 2 attempts, │ please try again later\n",
      "answer: It is an internet connectivity error, terraform is somehow not able to access the online registry. Check your VPN/Firewall settings (or just clear cookies or restart your network). Try terraform init again after this, it should work.\n",
      "\n",
      "section: Module 2: Workflow Orchestration\n",
      "question: Docker: container crashed with status code 137.\n",
      "answer: It means your container consumed all available RAM allocated to it. It can happen in particular when working on Question#3 in the homework as the dataset is relatively large and containers eat a lot of memory in general.\n",
      "I would recommend restarting your computer and only starting the necessary processes to run the container. If that doesn’t work, allocate more resources to docker. If also that doesn’t work because your workstation is a potato, you can use an online compute environment service like GitPod, which is free under under 50 hours / month of use.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
      "answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - how many Zoomcamps in a year?\n",
      "answer: There are 3 Zoom Camps in a year, as of 2024. However, they are for separate courses:\n",
      "Data-Engineering (Jan - Apr)\n",
      "MLOps (May - Aug)\n",
      "Machine Learning (Sep - Jan)\n",
      "There's only one Data-Engineering Zoomcamp “live” cohort per year, for the certification. Same as for the other Zoomcamps.\n",
      "They follow pretty much the same schedule for each cohort per zoomcamp. For Data-Engineering it is (generally) from Jan-Apr of the year. If you’re not interested in the Certificate, you can take any zoom camps at any time, at your own pace, out of sync with any “live” cohort.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Environment - Do I need both GitHub Codespaces and GCP?\n",
      "answer: Choose the approach that aligns the most with your idea for the end project\n",
      "One of those should suffice. However, BigQuery, which is part of GCP, will be used, so learning that is probably a better option. Or you can set up a local environment for most of this course.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Leaderboard - I am not on the leaderboard / how do I know which one I am on the leaderboard?\n",
      "answer: When you set up your account you are automatically assigned a random name such as “Lucid Elbakyan” for example. If you want to see what your Display name is.\n",
      "Go to the Homework submission link →  https://courses.datatalks.club/de-zoomcamp-2024/homework/hw2 - Log in > Click on ‘Data Engineering Zoom Camp 2024’ > click on ‘Edit Course Profile’ - your display name is here, you can also change it should you wish:\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - ​​How many hours per week am I expected to spend on this  course?\n",
      "answer: It depends on your background and previous experience with modules. It is expected to require about 5 - 15 hours per week. [source1] [source2]\n",
      "You can also calculate it yourself using this data and then update this answer.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The student is asking for specific guidance on how to be successful in their first module. I need to gather information about success strategies and tips that may have been documented in the FAQ database.\", \"keywords\": [\"success tips for module 1\", \"how to excel in module 1\", \"strategies for module success\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"Since the first search did not yield relevant information about success strategies for Module 1, I will look for broader resources on effective study habits and general tips for success in courses that might also apply to Module 1 specifically.\", \"keywords\": [\"effective study habits\", \"course success strategies\", \"tips for succeeding in online modules\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The previous searches did not return specific strategies for success in Module 1. I will focus on searching for any general or specific resources that discuss strategies for success in online learning and course completion that might be applicable to Module 1.\", \"keywords\": [\"online learning success strategies\", \"how to succeed in online courses\", \"tips for succeeding in academic modules\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER\",\n",
      "  \"answer\": \"To be successful in Module 1, it's important to adopt effective study habits and engage actively with the course material. Here are some general tips that can help: \\n1. **Establish a Study Schedule**: Dedicate specific hours each week to studying and stick to them to create a routine. \\n2. **Stay Organized**: Keep track of assignments, deadlines, and important dates related to the module. Use tools like calendars or task management apps. \\n3. **Engage with the Material**: Actively participate in discussions, forums, and any live sessions. Don't hesitate to ask questions if you're unclear about something. \\n4. **Practice Hands-On Skills**: If the module involves practical exercises, practice them thoroughly. Apply what you learn in real-world scenarios. \\n5. **Collaborate with Peers**: Consider forming study groups with fellow students to discuss concepts and solve problems together. \\n6. **Seek Feedback**: Submit assignments for review and seek feedback to improve your understanding and performance. \\n7. **Utilize Resources**: Make sure to take advantage of all resources provided by the course, including lectures, reading materials, and supplementary resources. These strategies should help you navigate Module 1 effectively.\",\n",
      "  \"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"what do I need to do to be successful at module 1?\"\n",
    "\n",
    "search_queries = []\n",
    "search_results = []\n",
    "previous_actions = []\n",
    "\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "while True:\n",
    "    print(f'ITERATION #{iteration}...')\n",
    "\n",
    "    context = build_context(search_results)\n",
    "    prompt = prompt_template.format(\n",
    "        question=question,\n",
    "        context=context,\n",
    "        search_queries=\"\\n\".join(search_queries),\n",
    "        previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "        max_iterations=3,\n",
    "        iteration_number=iteration\n",
    "    )\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(json.dumps(answer, indent=2))\n",
    "\n",
    "    previous_actions.append(answer)\n",
    "\n",
    "    action = answer['action']\n",
    "    if action != 'SEARCH':\n",
    "        break\n",
    "\n",
    "    keywords = answer['keywords']\n",
    "    search_queries = list(set(search_queries) | set(keywords))\n",
    "    \n",
    "    for k in keywords:\n",
    "        res = search(k)\n",
    "        search_results.extend(res)\n",
    "\n",
    "    search_results = dedup(search_results)\n",
    "    \n",
    "    iteration = iteration + 1\n",
    "    if iteration >= 4:\n",
    "        break\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3331e6fe-3fec-41ed-bfd7-4aae547ab418",
   "metadata": {},
   "source": [
    "Now let's make another iteration - use the same code as previously, but remove variable initialization and increase the iteration number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "045f6f70-b21f-4bd7-b9a5-1f0c3ce9b58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "how to succeed in online courses\n",
      "course success strategies\n",
      "success tips for module 1\n",
      "online learning success strategies\n",
      "effective study habits\n",
      "how to excel in module 1\n",
      "tips for succeeding in online modules\n",
      "strategies for module success\n",
      "tips for succeeding in academic modules\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Is it possible to use tool “X” instead of the one tool you use in the course?\n",
      "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
      "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
      "Should you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "\n",
      "section: General course-related questions\n",
      "question: Environment - Roadblock for Windows users in modules with *.sh (shell scripts).\n",
      "answer: Have no idea how past cohorts got past this as I haven't read old slack messages, and no FAQ entries that I can find.\n",
      "Later modules (module-05 & RisingWave workshop) use shell scripts in *.sh files and most Windows users not using WSL would hit a wall and cannot continue, even in git bash or MINGW64. This is why WSL environment setup is recommended from the start.\n",
      "\n",
      "section: Module 3: Data Warehousing\n",
      "question: GCS Bucket - I query my dataset and get a Bad character (ASCII 0) error?\n",
      "answer: Check the Schema\n",
      "You might have a wrong formatting\n",
      "Try to upload the CSV.GZ files without formatting or going through pandas via wget\n",
      "See this Slack conversation for helpful tips\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Hadoop - Exception in thread \"main\" java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z\n",
      "answer: If you are seeing this (or similar) error when attempting to write to parquet, it is likely an issue with your path variables.\n",
      "For Windows, create a new User Variable “HADOOP_HOME” that points to your Hadoop directory. Then add “%HADOOP_HOME%\\bin” to the PATH variable.\n",
      "Additional tips can be found here: https://stackoverflow.com/questions/41851066/exception-in-thread-main-java-lang-unsatisfiedlinkerror-org-apache-hadoop-io\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error: Failed to query available provider packages │ Could not retrieve the list of available versions for provider hashicorp/google: could not query │ provider registry for registry.terrafogorm.io/hashicorp/google: the request failed after 2 attempts, │ please try again later\n",
      "answer: It is an internet connectivity error, terraform is somehow not able to access the online registry. Check your VPN/Firewall settings (or just clear cookies or restart your network). Try terraform init again after this, it should work.\n",
      "\n",
      "section: Module 2: Workflow Orchestration\n",
      "question: Docker: container crashed with status code 137.\n",
      "answer: It means your container consumed all available RAM allocated to it. It can happen in particular when working on Question#3 in the homework as the dataset is relatively large and containers eat a lot of memory in general.\n",
      "I would recommend restarting your computer and only starting the necessary processes to run the container. If that doesn’t work, allocate more resources to docker. If also that doesn’t work because your workstation is a potato, you can use an online compute environment service like GitPod, which is free under under 50 hours / month of use.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
      "answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - how many Zoomcamps in a year?\n",
      "answer: There are 3 Zoom Camps in a year, as of 2024. However, they are for separate courses:\n",
      "Data-Engineering (Jan - Apr)\n",
      "MLOps (May - Aug)\n",
      "Machine Learning (Sep - Jan)\n",
      "There's only one Data-Engineering Zoomcamp “live” cohort per year, for the certification. Same as for the other Zoomcamps.\n",
      "They follow pretty much the same schedule for each cohort per zoomcamp. For Data-Engineering it is (generally) from Jan-Apr of the year. If you’re not interested in the Certificate, you can take any zoom camps at any time, at your own pace, out of sync with any “live” cohort.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Environment - Do I need both GitHub Codespaces and GCP?\n",
      "answer: Choose the approach that aligns the most with your idea for the end project\n",
      "One of those should suffice. However, BigQuery, which is part of GCP, will be used, so learning that is probably a better option. Or you can set up a local environment for most of this course.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Leaderboard - I am not on the leaderboard / how do I know which one I am on the leaderboard?\n",
      "answer: When you set up your account you are automatically assigned a random name such as “Lucid Elbakyan” for example. If you want to see what your Display name is.\n",
      "Go to the Homework submission link →  https://courses.datatalks.club/de-zoomcamp-2024/homework/hw2 - Log in > Click on ‘Data Engineering Zoom Camp 2024’ > click on ‘Edit Course Profile’ - your display name is here, you can also change it should you wish:\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - ​​How many hours per week am I expected to spend on this  course?\n",
      "answer: It depends on your background and previous experience with modules. It is expected to require about 5 - 15 hours per week. [source1] [source2]\n",
      "You can also calculate it yourself using this data and then update this answer.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The student is asking for specific guidance on how to be successful in their first module. I need to gather information about success strategies and tips that may have been documented in the FAQ database.\", \"keywords\": [\"success tips for module 1\", \"how to excel in module 1\", \"strategies for module success\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"Since the first search did not yield relevant information about success strategies for Module 1, I will look for broader resources on effective study habits and general tips for success in courses that might also apply to Module 1 specifically.\", \"keywords\": [\"effective study habits\", \"course success strategies\", \"tips for succeeding in online modules\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The previous searches did not return specific strategies for success in Module 1. I will focus on searching for any general or specific resources that discuss strategies for success in online learning and course completion that might be applicable to Module 1.\", \"keywords\": [\"online learning success strategies\", \"how to succeed in online courses\", \"tips for succeeding in academic modules\"]}\n",
      "{\"action\": \"ANSWER\", \"answer\": \"To be successful in Module 1, it's important to adopt effective study habits and engage actively with the course material. Here are some general tips that can help: \\n1. **Establish a Study Schedule**: Dedicate specific hours each week to studying and stick to them to create a routine. \\n2. **Stay Organized**: Keep track of assignments, deadlines, and important dates related to the module. Use tools like calendars or task management apps. \\n3. **Engage with the Material**: Actively participate in discussions, forums, and any live sessions. Don't hesitate to ask questions if you're unclear about something. \\n4. **Practice Hands-On Skills**: If the module involves practical exercises, practice them thoroughly. Apply what you learn in real-world scenarios. \\n5. **Collaborate with Peers**: Consider forming study groups with fellow students to discuss concepts and solve problems together. \\n6. **Seek Feedback**: Submit assignments for review and seek feedback to improve your understanding and performance. \\n7. **Utilize Resources**: Make sure to take advantage of all resources provided by the course, including lectures, reading materials, and supplementary resources. These strategies should help you navigate Module 1 effectively.\", \"source\": \"OWN_KNOWLEDGE\"}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER\",\n",
      "  \"answer\": \"To be successful in Module 1, it's important to adopt effective study habits and engage actively with the course material. Here are some general tips that can help: \\n1. **Establish a Study Schedule**: Dedicate specific hours each week to studying and stick to them to create a routine. \\n2. **Stay Organized**: Keep track of assignments, deadlines, and important dates related to the module. Use tools like calendars or task management apps. \\n3. **Engage with the Material**: Actively participate in discussions, forums, and any live sessions. Don't hesitate to ask questions if you're unclear about something. \\n4. **Practice Hands-On Skills**: If the module involves practical exercises, practice them thoroughly. Apply what you learn in real-world scenarios. \\n5. **Collaborate with Peers**: Consider forming study groups with fellow students to discuss concepts and solve problems together. \\n6. **Seek Feedback**: Submit assignments for review and seek feedback to improve your understanding and performance. \\n7. **Utilize Resources**: Make sure to take advantage of all resources provided by the course, including lectures, reading materials, and supplementary resources. These strategies should help you navigate Module 1 effectively.\",\n",
      "  \"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# question = \"how do I join the course?\"\n",
    "\n",
    "# search_queries = []\n",
    "# search_results = []\n",
    "# previous_actions = []\n",
    "\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=3,\n",
    "    iteration_number=2\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "answer_json = llm(prompt)\n",
    "answer = json.loads(answer_json)\n",
    "print(json.dumps(answer, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffb1c8c-bca5-4a36-8e8f-59290deaa241",
   "metadata": {},
   "source": [
    "Let's put everything together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ec0b5ba-907a-4513-9491-e51245b5d8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"I need to gather information about best practices and strategies for succeeding in module 1, which may be outlined in the FAQ database.\",\n",
      "  \"keywords\": [\n",
      "    \"success in module 1\",\n",
      "    \"module 1 tips\",\n",
      "    \"how to excel in module 1\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #1...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "success in module 1\n",
      "module 1 tips\n",
      "how to excel in module 1\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"I need to gather information about best practices and strategies for succeeding in module 1, which may be outlined in the FAQ database.\", \"keywords\": [\"success in module 1\", \"module 1 tips\", \"how to excel in module 1\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"To provide more specific tips and guidelines for success in module 1, I need to look for information related to effective study habits, recommended resources, and strategies that may be available in the FAQ database.\",\n",
      "  \"keywords\": [\n",
      "    \"module 1 study tips\",\n",
      "    \"how to succeed in Docker and Terraform\",\n",
      "    \"best practices for module 1\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #2...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "module 1 study tips\n",
      "how to succeed in Docker and Terraform\n",
      "how to excel in module 1\n",
      "success in module 1\n",
      "module 1 tips\n",
      "best practices for module 1\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error: Failed to query available provider packages │ Could not retrieve the list of available versions for provider hashicorp/google: could not query │ provider registry for registry.terrafogorm.io/hashicorp/google: the request failed after 2 attempts, │ please try again later\n",
      "answer: It is an internet connectivity error, terraform is somehow not able to access the online registry. Check your VPN/Firewall settings (or just clear cookies or restart your network). Try terraform init again after this, it should work.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error acquiring the state lock\n",
      "answer: https://github.com/hashicorp/terraform/issues/14513\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Where can I find the Terraform 1.1.3 Linux (AMD 64)?\n",
      "answer: Here: https://releases.hashicorp.com/terraform/1.1.3/terraform_1.1.3_linux_amd64.zip\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Terraform initialized in an empty directory! The directory has no Terraform configuration files. You may begin working with Terraform immediately by creating Terraform configuration files.g\n",
      "answer: You get this error because I run the command terraform init outside the working directory, and this is wrong.You need first to navigate to the working directory that contains terraform configuration files, and and then run the command.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error 400 Bad Request.  Invalid JWT Token  on WSL.\n",
      "answer: When running\n",
      "terraform apply\n",
      "on wsl2 I've got this error:\n",
      "│ Error: Post \"https://storage.googleapis.com/storage/v1/b?alt=json&prettyPrint=false&project=<your-project-id>\": oauth2: cannot fetch token: 400 Bad Request\n",
      "│ Response: {\"error\":\"invalid_grant\",\"error_description\":\"Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.\"}\n",
      "IT happens because there may be time desync on your machine which affects computing JWT\n",
      "To fix this, run the command\n",
      "sudo hwclock -s\n",
      "which fixes your system time.\n",
      "Reference\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Docker - cs to store all code in your default Linux distro to get the best out of file system performance (since Docker runs on WSL2 backend by default for Windows 10 Home / Windows 11 Home users).\n",
      "answer: More info in the Docker Docs on Best Practises\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"I need to gather information about best practices and strategies for succeeding in module 1, which may be outlined in the FAQ database.\", \"keywords\": [\"success in module 1\", \"module 1 tips\", \"how to excel in module 1\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide more specific tips and guidelines for success in module 1, I need to look for information related to effective study habits, recommended resources, and strategies that may be available in the FAQ database.\", \"keywords\": [\"module 1 study tips\", \"how to succeed in Docker and Terraform\", \"best practices for module 1\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"I need to find additional resources or tips specifically tailored for students to excel in Module 1, particularly focusing on Docker and Terraform. This will help provide a more comprehensive answer regarding success strategies and tips for the module.\",\n",
      "  \"keywords\": [\n",
      "    \"Module 1 resources\",\n",
      "    \"Docker and Terraform study strategies\",\n",
      "    \"tips for succeeding in Docker and Terraform\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #3...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 3. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "Module 1 resources\n",
      "how to succeed in Docker and Terraform\n",
      "how to excel in module 1\n",
      "success in module 1\n",
      "module 1 tips\n",
      "module 1 study tips\n",
      "Docker and Terraform study strategies\n",
      "best practices for module 1\n",
      "tips for succeeding in Docker and Terraform\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error: Failed to query available provider packages │ Could not retrieve the list of available versions for provider hashicorp/google: could not query │ provider registry for registry.terrafogorm.io/hashicorp/google: the request failed after 2 attempts, │ please try again later\n",
      "answer: It is an internet connectivity error, terraform is somehow not able to access the online registry. Check your VPN/Firewall settings (or just clear cookies or restart your network). Try terraform init again after this, it should work.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error acquiring the state lock\n",
      "answer: https://github.com/hashicorp/terraform/issues/14513\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Where can I find the Terraform 1.1.3 Linux (AMD 64)?\n",
      "answer: Here: https://releases.hashicorp.com/terraform/1.1.3/terraform_1.1.3_linux_amd64.zip\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Terraform initialized in an empty directory! The directory has no Terraform configuration files. You may begin working with Terraform immediately by creating Terraform configuration files.g\n",
      "answer: You get this error because I run the command terraform init outside the working directory, and this is wrong.You need first to navigate to the working directory that contains terraform configuration files, and and then run the command.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error 400 Bad Request.  Invalid JWT Token  on WSL.\n",
      "answer: When running\n",
      "terraform apply\n",
      "on wsl2 I've got this error:\n",
      "│ Error: Post \"https://storage.googleapis.com/storage/v1/b?alt=json&prettyPrint=false&project=<your-project-id>\": oauth2: cannot fetch token: 400 Bad Request\n",
      "│ Response: {\"error\":\"invalid_grant\",\"error_description\":\"Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.\"}\n",
      "IT happens because there may be time desync on your machine which affects computing JWT\n",
      "To fix this, run the command\n",
      "sudo hwclock -s\n",
      "which fixes your system time.\n",
      "Reference\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Docker - cs to store all code in your default Linux distro to get the best out of file system performance (since Docker runs on WSL2 backend by default for Windows 10 Home / Windows 11 Home users).\n",
      "answer: More info in the Docker Docs on Best Practises\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing\n",
      "answer: Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: WSL - Insufficient system resources exist to complete the requested service.\n",
      "answer: Cause:\n",
      "It happens because the apps are not updated. To be specific, search for any pending updates for Windows Terminal, WSL and Windows Security updates.\n",
      "Solution\n",
      "for updating Windows terminal which worked for me:\n",
      "Go to Microsoft Store.\n",
      "Go to the library of apps installed in your system.\n",
      "Search for Windows terminal.\n",
      "Update the app and restart your system to  see the changes.\n",
      "For updating the Windows security updates:\n",
      "Go to Windows updates and check if there are any pending updates from Windows, especially security updates.\n",
      "Do restart your system once the updates are downloaded and installed successfully.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"I need to gather information about best practices and strategies for succeeding in module 1, which may be outlined in the FAQ database.\", \"keywords\": [\"success in module 1\", \"module 1 tips\", \"how to excel in module 1\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide more specific tips and guidelines for success in module 1, I need to look for information related to effective study habits, recommended resources, and strategies that may be available in the FAQ database.\", \"keywords\": [\"module 1 study tips\", \"how to succeed in Docker and Terraform\", \"best practices for module 1\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"I need to find additional resources or tips specifically tailored for students to excel in Module 1, particularly focusing on Docker and Terraform. This will help provide a more comprehensive answer regarding success strategies and tips for the module.\", \"keywords\": [\"Module 1 resources\", \"Docker and Terraform study strategies\", \"tips for succeeding in Docker and Terraform\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER\",\n",
      "  \"answer\": \"To be successful in Module 1 which focuses on Docker and Terraform, it's important to understand a few key strategies:\\n\\n1. **Familiarize with the Tools:** Ensure you have a strong grasp of both Docker and Terraform. Install them and run through basic commands and functionalities.\\n\\n2. **Practice Regularly:** Implementing what you've learned through hands-on exercises is crucial. Create sample projects that utilize Docker containers and Terraform configurations.\\n\\n3. **Utilize Resources:** Make use of any recommended readings, video tutorials, and documentation available for both Docker and Terraform. Understanding the official documentation can greatly enhance your learning.\\n\\n4. **Engage with the Community:** Participate in forums, such as Stack Overflow or GitHub discussions, to ask questions and share knowledge. Learning from others\\u2019 experiences can provide valuable insights.\\n\\n5. **Work on Real-world Projects:** If possible, try to work on personal or collaborative projects that integrate Docker and Terraform. This will provide practical experience and reinforce your understanding of the concepts.\\n\\n6. **Time Management:** Dedicate specific times for studying and practicing each topic within the module. Keeping a consistent study schedule can greatly enhance retention.\\n\\n7. **Obstacle Management:** Be prepared to encounter errors and issues; understanding how to troubleshoot is a key part of working with these technologies. Look up solutions and ask for help if needed.\\n\\nBy following these strategies, you'll be well-positioned to succeed in Module 1.\",\n",
      "  \"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"what do I need to do to be successful at module 1?\"\n",
    "\n",
    "search_queries = []\n",
    "search_results = []\n",
    "previous_actions = []\n",
    "\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "while True:\n",
    "    print(f'ITERATION #{iteration}...')\n",
    "\n",
    "    context = build_context(search_results)\n",
    "    prompt = prompt_template.format(\n",
    "        question=question,\n",
    "        context=context,\n",
    "        search_queries=\"\\n\".join(search_queries),\n",
    "        previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "        max_iterations=3,\n",
    "        iteration_number=iteration\n",
    "    )\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(json.dumps(answer, indent=2))\n",
    "\n",
    "    previous_actions.append(answer)\n",
    "\n",
    "    action = answer['action']\n",
    "    if action != 'SEARCH':\n",
    "        break\n",
    "\n",
    "    keywords = answer['keywords']\n",
    "    search_queries = list(set(search_queries) | set(keywords))\n",
    "    \n",
    "    for k in keywords:\n",
    "        res = search(k)\n",
    "        search_results.extend(res)\n",
    "\n",
    "    search_results = dedup(search_results)\n",
    "    \n",
    "    iteration = iteration + 1\n",
    "    if iteration >= 4:\n",
    "        break\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9933efeb-344a-4201-9d17-75a27d1eeab8",
   "metadata": {},
   "source": [
    "Or, as a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f310df3d-30b9-462c-aa23-5179e217baab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agentic_search(question):\n",
    "    search_queries = []\n",
    "    search_results = []\n",
    "    previous_actions = []\n",
    "\n",
    "    iteration = 0\n",
    "    \n",
    "    while True:\n",
    "        print(f'ITERATION #{iteration}...')\n",
    "    \n",
    "        context = build_context(search_results)\n",
    "        prompt = prompt_template.format(\n",
    "            question=question,\n",
    "            context=context,\n",
    "            search_queries=\"\\n\".join(search_queries),\n",
    "            previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "            max_iterations=3,\n",
    "            iteration_number=iteration\n",
    "        )\n",
    "    \n",
    "        print(prompt)\n",
    "    \n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(json.dumps(answer, indent=2))\n",
    "\n",
    "        previous_actions.append(answer)\n",
    "    \n",
    "        action = answer['action']\n",
    "        if action != 'SEARCH':\n",
    "            break\n",
    "    \n",
    "        keywords = answer['keywords']\n",
    "        search_queries = list(set(search_queries) | set(keywords))\n",
    "\n",
    "        for k in keywords:\n",
    "            res = search(k)\n",
    "            search_results.extend(res)\n",
    "    \n",
    "        search_results = dedup(search_results)\n",
    "        \n",
    "        iteration = iteration + 1\n",
    "        if iteration >= 4:\n",
    "            break\n",
    "    \n",
    "        print()\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ce21d8-bd79-4bb8-8440-79134cb0fac1",
   "metadata": {},
   "source": [
    "Test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fadf3e2b-d201-4182-8863-dc12237b20d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I prepare for the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"The question is about preparation for the course, which likely involves understanding prerequisites, resources, study tips, and other related topics. I need to gather relevant information from the FAQ database that can help answer this question comprehensively.\",\n",
      "  \"keywords\": [\n",
      "    \"course preparation\",\n",
      "    \"how to prepare for the course\",\n",
      "    \"study tips\",\n",
      "    \"prerequisites for the course\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #1...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I prepare for the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "study tips\n",
      "course preparation\n",
      "how to prepare for the course\n",
      "prerequisites for the course\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Is it possible to use tool “X” instead of the one tool you use in the course?\n",
      "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
      "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
      "Should you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "\n",
      "section: Module 3: Data Warehousing\n",
      "question: GCS Bucket - I query my dataset and get a Bad character (ASCII 0) error?\n",
      "answer: Check the Schema\n",
      "You might have a wrong formatting\n",
      "Try to upload the CSV.GZ files without formatting or going through pandas via wget\n",
      "See this Slack conversation for helpful tips\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Hadoop - Exception in thread \"main\" java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z\n",
      "answer: If you are seeing this (or similar) error when attempting to write to parquet, it is likely an issue with your path variables.\n",
      "For Windows, create a new User Variable “HADOOP_HOME” that points to your Hadoop directory. Then add “%HADOOP_HOME%\\bin” to the PATH variable.\n",
      "Additional tips can be found here: https://stackoverflow.com/questions/41851066/exception-in-thread-main-java-lang-unsatisfiedlinkerror-org-apache-hadoop-io\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - What are the prerequisites for this course?\n",
      "answer: GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - What can I do before the course starts?\n",
      "answer: You can start by installing and setting up all the dependencies and requirements:\n",
      "Google cloud account\n",
      "Google Cloud SDK\n",
      "Python 3 (installed with Anaconda)\n",
      "Terraform\n",
      "Git\n",
      "Look over the prerequisites and syllabus to see if you are comfortable with these subjects.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The question is about preparation for the course, which likely involves understanding prerequisites, resources, study tips, and other related topics. I need to gather relevant information from the FAQ database that can help answer this question comprehensively.\", \"keywords\": [\"course preparation\", \"how to prepare for the course\", \"study tips\", \"prerequisites for the course\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER_CONTEXT\",\n",
      "  \"answer\": \"To prepare for the course, you can start by installing and setting up all the dependencies and requirements such as a Google Cloud account, Google Cloud SDK, Python 3 (installed with Anaconda), Terraform, and Git. It's also helpful to look over the prerequisites and syllabus to ensure you are comfortable with the subjects covered in the course.\",\n",
      "  \"source\": \"CONTEXT\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER_CONTEXT',\n",
       " 'answer': \"To prepare for the course, you can start by installing and setting up all the dependencies and requirements such as a Google Cloud account, Google Cloud SDK, Python 3 (installed with Anaconda), Terraform, and Git. It's also helpful to look over the prerequisites and syllabus to ensure you are comfortable with the subjects covered in the course.\",\n",
       " 'source': 'CONTEXT'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentic_search('how do I prepare for the course?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611adba8-f26d-423f-a778-64f74d9e7079",
   "metadata": {},
   "source": [
    "## Part 3: Function calling\n",
    "---\n",
    "Function calling in OpenAI\n",
    "\n",
    "We put all this logic inside our prompt.\n",
    "\n",
    "But OpenAI and other providers provide a convenient API for adding extra functionality like search.\n",
    "\n",
    "* https://platform.openai.com/docs/guides/function-calling\n",
    "\n",
    "It's called \"function calling\" - you define functions that the model can call, and if it decides to make a call, it returns structured output for that.\n",
    "\n",
    "For example, let's take our ```search``` function:\n",
    "\n",
    "```python\n",
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b10ef9-8988-4df4-b815-d31a3070f5d5",
   "metadata": {},
   "source": [
    "We describe it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3803e849-af36-4449-a162-487871736668",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"search\",\n",
    "    \"description\": \"Search the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query text to look up in the course FAQ.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d056717b-bdf0-4185-aca8-e66f8415ff93",
   "metadata": {},
   "source": [
    "Here we have:\n",
    "\n",
    "* ```name```: ```search```\n",
    "* ```description```: when to use it\n",
    "* ```parameters```: all the arguments that the function can take and their description\n",
    "\n",
    "In order to use function calling, we'll use a newer API - the \"responses\" API (not \"chat completions\" as previously):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44805f07-367d-4da3-8acb-4ec8155c637a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseFunctionToolCall(arguments='{\"query\":\"how to do well in module 1\"}', call_id='call_befB3lvsaKwzDMpGt6lV4pr4', name='search', type='function_call', id='fc_68759bc43da8819fab1069a02b9729f207b195572084d1dd', status='completed')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How do I do well in module 1?\"\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\"\"\".strip()\n",
    "\n",
    "tools = [search_tool]\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")\n",
    "response.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163000a6-86bf-4560-9145-cfc68447ae70",
   "metadata": {},
   "source": [
    "If the model thinks we should make a function call, it will tell us:\n",
    "\n",
    "```[ResponseFunctionToolCall(arguments='{\"query\":\"How to do well in module 1\"}', call_id='call_AwYwOak5Ljeidh4HbE3RxMZJ', name='search', type='function_call', id='fc_6848604db67881a298ec38121c1555ef0dee5fa0cdb59912', status='completed')]```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f077e3ed-5c8b-446e-b82b-b4bb5dcf62a7",
   "metadata": {},
   "source": [
    "Let's make a call to ```search```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12fdba5b-78f3-495c-9227-f8c7df348a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'how to do well in module 1'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calls = response.output\n",
    "call = calls[0]\n",
    "call\n",
    "\n",
    "call_id = call.call_id\n",
    "call_id\n",
    "\n",
    "f_name = call.name\n",
    "f_name\n",
    "\n",
    "arguments = json.loads(call.arguments)\n",
    "arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f919aea-a3a7-4354-9e5b-4312083e4f97",
   "metadata": {},
   "source": [
    "Using ```f_name``` we can find the function we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2963fd6-2e71-4bb9-89ef-c0b8f6e3f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = globals()[f_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84400e10-ebba-4731-8b21-59fb39287317",
   "metadata": {},
   "source": [
    "And invoke it with arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebea193c-6b8a-4e4b-a5e3-694cdd65df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = f(**arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cbfebc-1c70-433c-b1c9-2cf1c1e6c69f",
   "metadata": {},
   "source": [
    "Now, let's save the results as json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "335b111a-23bf-4f9b-9384-45c821ef21d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\\\"Murray Hill\\\") & (new_final.b_zone==\\\"Midwood\\\")).show()\\nKrishna Anand\",\n",
      "    \"section\": \"Module 5: pyspark\",\n",
      "    \"question\": \"Module Not Found Error in Jupyter Notebook .\",\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"_id\": 322\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\u201d\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\"` appropriately.\\nAdditionally, you can check for the version of \\u2018py4j\\u2019 of the spark you\\u2019re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\",\n",
      "    \"section\": \"Module 5: pyspark\",\n",
      "    \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\",\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"_id\": 323\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\n",
      "    \"section\": \"Module 4: analytics engineering with dbt\",\n",
      "    \"question\": \"DBT - Error: No module named 'pytz' while setting up dbt with docker\",\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"_id\": 299\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \\\"TypeError: 'module' object is not callable\\\"\\nSolution:\\nconn_string = \\\"postgresql+psycopg://root:root@localhost:5432/ny_taxi\\\"\\nengine = create_engine(conn_string)\",\n",
      "    \"section\": \"Module 1: Docker and Terraform\",\n",
      "    \"question\": \"Python - SQLALchemy - TypeError 'module' object is not callable\",\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"_id\": 124\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"Error raised during the jupyter notebook\\u2019s cell execution:\\nengine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\\nSolution: Need to install Python module \\u201cpsycopg2\\u201d. Can be installed by Conda or pip.\",\n",
      "    \"section\": \"Module 1: Docker and Terraform\",\n",
      "    \"question\": \"Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\",\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"_id\": 125\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "search_results = json.dumps(results, indent=2)\n",
    "print(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc4d23-3ca2-4253-b975-bf54b25dfb0f",
   "metadata": {},
   "source": [
    "And save both the response and the result of the function call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b666cb9b-47e3-4464-add6-d7b0dd696db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_messages.append(call)\n",
    "\n",
    "chat_messages.append({\n",
    "    \"type\": \"function_call_output\",\n",
    "    \"call_id\": call.call_id,\n",
    "    \"output\": search_results,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4558a4ec-0caf-4c8d-98a3-4c51629f59cb",
   "metadata": {},
   "source": [
    "Now ```chat_messages```response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ") contains both the call description (so it keeps track of history) and the results\n",
    "\n",
    "Let's make another call to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "202a4aaa-c87d-4e2a-a083-22dcdeeb74e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e39580b-8a5a-4a14-ba8c-3b3fb7b31d77",
   "metadata": {},
   "source": [
    "This time is should be teh response (but also can be another call):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45de122b-6315-4467-9c71-05256abe9078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To do well in Module 1 of the course, here are some tips:\n",
      "\n",
      "1. **Understand the Content**: Familiarize yourself with the key topics covered in Module 1, which focuses on Docker and Terraform. Make sure to review any associated materials or videos provided.\n",
      "\n",
      "2. **Hands-On Practice**: Actively engage with the hands-on exercises. Set up Docker and Terraform on your local machine, and practice building and deploying services as described in the module.\n",
      "\n",
      "3. **Troubleshoot Common Errors**: Be aware of potential issues others have faced, such as:\n",
      "   - **SQLAlchemy Errors**: If you encounter the error `TypeError: 'module' object is not callable`, ensure your connection string is correct. You may need to adjust it to use the appropriate format.\n",
      "   - **Module Not Found Errors**: If you get a `ModuleNotFoundError` for `psycopg2`, ensure you install it using pip or Conda.\n",
      "\n",
      "4. **Ask Questions**: If you're stuck, don’t hesitate to reach out to your peers or instructors for clarification on challenging topics.\n",
      "\n",
      "5. **Participate in Discussions**: Engage with fellow students in forums or discussion groups to share insights and tips.\n",
      "\n",
      "6. **Review and Revise**: Regularly revisit the module's materials to reinforce your learning and identify areas needing further attention.\n",
      "\n",
      "By following these steps, you should enhance your understanding and performance in Module 1!\n"
     ]
    }
   ],
   "source": [
    "r = response.output[0]\n",
    "print(r.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b57bcf-a475-46e6-a438-f18eaf0919bd",
   "metadata": {},
   "source": [
    "## Making multiple calls\n",
    "---\n",
    "What if we want to make multiple calls? Change the developer prompt a little:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb3c1a94-c87c-4360-aaae-7cc82872abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "If you look up something in FAQ, convert the student question into multiple queries.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f078a2-9dce-475d-ad0b-106941bec074",
   "metadata": {},
   "source": [
    "This time let's start to organize the code a little:\n",
    "\n",
    "Let's organize our code a little.\n",
    "\n",
    "First, create a function ```do_call```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8997f7fa-d7aa-4bc2-a49b-f3a21a12a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_call(tool_call_response):\n",
    "    function_name = tool_call_response.name\n",
    "    arguments = json.loads(tool_call_response.arguments)\n",
    "\n",
    "    f = globals()[function_name]\n",
    "    result = f(**arguments)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"function_call_output\",\n",
    "        \"call_id\": tool_call_response.call_id,\n",
    "        \"output\": json.dumps(result, indent=2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f4db3a-d6fd-48e9-b119-8cfffacec416",
   "metadata": {},
   "source": [
    "Now iterate over responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8a2d002-eb13-4b3c-8882-2b2de7e6afe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function_call\n",
      "function_call\n"
     ]
    }
   ],
   "source": [
    "for entry in response.output:\n",
    "    chat_messages.append(entry)\n",
    "    print(entry.type)\n",
    "\n",
    "    if entry.type == 'function_call':      \n",
    "        result = do_call(entry)\n",
    "        chat_messages.append(result)\n",
    "    elif entry.type == 'message':\n",
    "        print(entry.text) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec156a48-988b-428a-8859-4b837333267b",
   "metadata": {},
   "source": [
    "First call will probable be a function call, so let's do another one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c07bba8-4c0d-44f5-9058-a5e5e113a8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message\n",
      "\n",
      "To do well in Module 1, consider the following tips:\n",
      "\n",
      "1. **Understand the Tools**: Familiarize yourself with Docker and Terraform, as these are essential tools in this module. Ensure you follow the installation instructions carefully to avoid common pitfalls.\n",
      "\n",
      "2. **Python Dependencies**: \n",
      "   - You might encounter errors related to missing Python modules. For instance, if you see `ModuleNotFoundError: No module named 'psycopg2'`, remember to install it using:\n",
      "     ```bash\n",
      "     pip install psycopg2-binary\n",
      "     ```\n",
      "   - If this does not resolve the issue, try updating pip or conda first and then reinstall the package.\n",
      "\n",
      "3. **Use Proper Connection Strings**: When working with SQLAlchemy, make sure your connection string is correctly formatted. For example:\n",
      "   ```python\n",
      "   conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "   engine = create_engine(conn_string)\n",
      "   ```\n",
      "   This helps avoid errors such as `TypeError: 'module' object is not callable`.\n",
      "\n",
      "4. **Practice and Troubleshoot**: Engage with practice exercises provided in the module. If you experience issues, troubleshooting specific error messages (like module not found errors) will reinforce your learning.\n",
      "\n",
      "5. **Follow Course Guidelines**: Always refer to the course materials and follow recommended best practices outlined in lectures and assignments.\n",
      "\n",
      "If you have specific questions or need clarification on any topics within Module 1, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "for entry in response.output:\n",
    "    chat_messages.append(entry)\n",
    "    print(entry.type)\n",
    "    print()\n",
    "\n",
    "    if entry.type == 'function_call':      \n",
    "        result = do_call(entry)\n",
    "        chat_messages.append(result)\n",
    "    elif entry.type == 'message':\n",
    "        print(entry.content[0].text) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecdb1da-0914-4833-847e-50cc8e1b8188",
   "metadata": {},
   "source": [
    "This one is a text response.\n",
    "\n",
    "### Putting everything together\n",
    "---\n",
    "But what if it's not?\n",
    "\n",
    "Let's make two loops:\n",
    "\n",
    "* First is the main Q&A loop - ask question, get back the answer\n",
    "* Second is the request loop - send requests until there's a message reply from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "012eee73-4c6f-4fd3-9a64-eb6d788df70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "When using FAQ, perform deep topic exploration: make one request to FAQ,\n",
    "and then based on the results, make more requests.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "704eeb17-54dd-43c8-93e7-d6d4ee50a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like your message didn't come through. Could you please ask your question again? I'm here to help!\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " How do I do my best for module 1?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function_call: ResponseFunctionToolCall(arguments='{\"query\":\"best practices for Module 1\"}', call_id='call_wKdwWTbu41jLsd9vktIPouXk', name='search', type='function_call', id='fc_68759fad677081a29923d4a7759e99bc0f1ef1ffdba70d68', status='completed')\n",
      "\n",
      "function_call: ResponseFunctionToolCall(arguments='{\"query\":\"how to succeed in Module 1 Docker and Terraform\"}', call_id='call_ohO12QbnkZ4bZnvlrpcLbsjz', name='search', type='function_call', id='fc_68759fae30a881a29c454cbcd730531b0f1ef1ffdba70d68', status='completed')\n",
      "\n",
      "To excel in Module 1, which focuses on Docker and Terraform, here are some best practices and tips tailored for you:\n",
      "\n",
      "1. **Understand Docker Basics**: \n",
      "   - Familiarize yourself with Docker's core concepts such as images, containers, and Dockerfiles. Resources like the [Docker Docs](https://docs.docker.com/) can provide detailed examples.\n",
      "\n",
      "2. **Utilize WSL2**: \n",
      "   - If you are using Windows, ensure that Docker runs on the WSL2 backend for better file system performance. This is particularly beneficial for Windows 10/11 Home users.\n",
      "\n",
      "3. **Follow the Course Instructions**: \n",
      "   - Carefully go through the course materials and follow the instructions step-by-step. Make sure you're working in the correct directory when executing Terraform commands to avoid errors, such as `Terraform initialized in an empty directory`.\n",
      "\n",
      "4. **Set Up Required Tools**:\n",
      "   - Make sure you have all the necessary tools installed, such as Terraform and Docker. For Terraform, it's important to declare your project name correctly in your configurations to avoid permissions issues when creating resources.\n",
      "\n",
      "5. **Configure Your Environment**:\n",
      "   - If using a VPN, ensure that it doesn't block necessary connections. Some students have faced network-related issues, so check your settings if you encounter connectivity problems with tools like Terraform.\n",
      "\n",
      "6. **Error Troubleshooting**:\n",
      "   - Don't hesitate to troubleshoot errors actively. For instance, if you face issues with permissions, review your access configurations; errors like `Permission denied on resource` can often be resolved by confirming your role permissions on GCP.\n",
      "\n",
      "7. **Community Engagement**:\n",
      "   - Engage with the community, whether on forums, chat groups, or during office hours. If you have specific questions, seeking help from peers or instructors can provide you with more insights.\n",
      "\n",
      "8. **Practice**: \n",
      "   - Rehearse as much as you can. Use practical exercises to reinforce learning and ensure that you are implementing the concepts taught in class.\n",
      "\n",
      "By applying these strategies, you should be able to make the most out of Module 1.\n",
      "\n",
      "What specific areas of the module are you finding most challenging?\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m: \u001b[38;5;66;03m# main Q&A loop\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     question = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# How do I do my best for module 1?\u001b[39;00m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m question == \u001b[33m'\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m      4\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py:1282\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1280\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1282\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1283\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1284\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1285\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1287\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py:1325\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1323\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1324\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1327\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True: # main Q&A loop\n",
    "    question = input() # How do I do my best for module 1?\n",
    "    if question == 'stop':\n",
    "        break\n",
    "\n",
    "    message = {\"role\": \"user\", \"content\": question}\n",
    "    chat_messages.append(message)\n",
    "\n",
    "    while True: # request-response loop - query API till get a message\n",
    "        response = client.responses.create(\n",
    "            model='gpt-4o-mini',\n",
    "            input=chat_messages,\n",
    "            tools=tools\n",
    "        )\n",
    "\n",
    "        has_messages = False\n",
    "        \n",
    "        for entry in response.output:\n",
    "            chat_messages.append(entry)\n",
    "        \n",
    "            if entry.type == 'function_call':      \n",
    "                print('function_call:', entry)\n",
    "                print()\n",
    "                result = do_call(entry)\n",
    "                chat_messages.append(result)\n",
    "            elif entry.type == 'message':\n",
    "                print(entry.content[0].text)\n",
    "                print()\n",
    "                has_messages = True\n",
    "\n",
    "        if has_messages:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a81155e-ad35-4024-b629-03e9508015fe",
   "metadata": {},
   "source": [
    "It's also possible that there's both message and tool calls, but we'll ignore this case for now. (It's easy to fix - just check if there are no function calls, and only then ask the user for input.)\n",
    "\n",
    "Let's make it a bit nicer using HTML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd0faafd-df50-46ed-9192-d98327950c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting markdown\n",
      "  Downloading markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Downloading markdown-3.8.2-py3-none-any.whl (106 kB)\n",
      "Installing collected packages: markdown\n",
      "Successfully installed markdown-3.8.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0166b235-58de-4e22-9a82-ed9bb5cc63f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'display_function_call' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     43\u001b[39m     result = do_call(entry)\n\u001b[32m     44\u001b[39m     chat_messages.append(result)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[43mdisplay_function_call\u001b[49m(entry, result)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m entry.type == \u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     48\u001b[39m     display_response(entry)\n",
      "\u001b[31mNameError\u001b[39m: name 'display_function_call' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "import markdown # pip install markdown\n",
    "\n",
    "    \n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "]\n",
    "\n",
    "# Chat loop\n",
    "while True:\n",
    "    \n",
    "    if question.strip().lower() == 'stop':\n",
    "        print(\"Chat ended.\")\n",
    "        break\n",
    "    print()\n",
    "\n",
    "    message = {\"role\": \"user\", \"content\": question}\n",
    "    chat_messages.append(message)\n",
    "\n",
    "    while True:  # inner request loop\n",
    "        response = client.responses.create(\n",
    "            model='gpt-4o-mini',\n",
    "            input=chat_messages,\n",
    "            tools=tools\n",
    "        )\n",
    "\n",
    "        has_messages = False\n",
    "\n",
    "        for entry in response.output:\n",
    "            chat_messages.append(entry)\n",
    "\n",
    "            if entry.type == \"function_call\":\n",
    "                result = do_call(entry)\n",
    "                chat_messages.append(result)\n",
    "                display_function_call(entry, result)\n",
    "\n",
    "            elif entry.type == \"message\":\n",
    "                display_response(entry)\n",
    "                has_messages = True\n",
    "\n",
    "        if has_messages:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
